# 决策树(上)：要不要去打篮球？决策树告诉你

## 决策树的工作原理

我们在做决策树的时候，会经历两个阶段：*构造和剪枝*。

![图片alt](https://static001.geekbang.org/resource/image/dc/90/dca4224b342894f12f54a9cb41d8cd90.jpg''图片title'') 

### 构造：

*构造的过程就是选择什么属性作为节点的过程*，那么在构造过程中，会存在三种节点：

1.根节点：就是树的最顶端，最开始的那个节点。在上图中，"天气"就是一个根节点；

2.内部节点：就是树中间的那些节点，比如说"温度"、"湿度"、"刮风";

3.叶部节点：就是树最底部的节点，也就是决策结果。



节点之间存在父子关系。比如根节点会有子节点，子节点会有子子节点，但是到了叶节点就会停止了，叶节点不存在子节点。那么在构造过程中，需要解决三个重要的问题：

1.选择哪个属性作为根节点；

2.选择哪些属性作为子节点；

3.什么时候停止并得到目标状态，即叶节点。



### 剪枝：

剪枝就是给决策树瘦身，剪枝的目的就是为了防止"过拟合"（Overfitting）现象的发生。

"过拟合"这个概念你一定要理解，它指的就是模型的训练结果"太好了",以至于在实际应用的

过程中，会存在"死板"的情况，导致分类错误。

泛化能力指的分类器是通过训练集抽象出来的分类能力，你也可以理解是举一反三的能力。

剪枝可以分为"预剪枝"和"后剪枝"。

预剪枝：是在决策树构造时就进行剪枝。

后剪枝：就是在生产决策树之后再进行剪枝，通常从决策树的叶节点开始，逐层向上对每个节点进行评估。



### 如何判断要不要去打球？

打篮球的数据集，训练数据如下：



![图片alt](https://static001.geekbang.org/resource/image/32/07/327eafa4a33e3e76ca86ac59195c0307.png ''图片title'')



如何构造一个判断是否去打篮球的决策树呢？

作为根节点的两个指标：*纯度和*信息熵

信息熵：它表示了信息的不确定度。

公式：

![](https://static001.geekbang.org/resource/image/74/d5/741f0ed01c53fd53f0e75204542abed5.png)

假设有2个集合

- 集合1：5次去打篮球，1次不去打篮球
- 集合2：3次去打篮球，3次不去不去打篮球

集合1中信息熵公式：![](https://static001.geekbang.org/resource/image/ab/a4/aba6bb24c3444923bfa2320119ce54a4.png)

集合2中信息熵公式：![](https://static001.geekbang.org/resource/image/e0/c2/e05fe27109330b49453b62505e37e4c2.png)

信息熵越大，纯度越低。当集合中的所有样本均匀混合时，信息熵最大，纯度最低。



经典的"不纯度"的指标有三种，分别是

- 信息增益(ID3算法)

ID3算法计算的是**信息增益**，信息增益指的就是划分可以带来纯度的提高，信息熵的下降。

计算公式：![](https://static001.geekbang.org/resource/image/bf/34/bfea7626733fff6180341c9dda3d4334.png)

公式中D是父节点，Di是子节点，Gain(D，a)中a作为D节点的属性选择

假设天气等于晴的时候，会有5次去打篮球，5次不打篮球。其中D1刮风=是，有2次打篮球，1次不打篮球。D2刮风=否，有3次打篮球。那么a代表节点的属性，即天气=晴。

![](https://static001.geekbang.org/resource/image/40/67/40810468abc4140f45f3a09a2d427667.jpg)

针对图上这个例子，D作为节点的信息增益为：

![](https://static001.geekbang.org/resource/image/f2/82/f23f88a18b1227398c2ab3ef445d5382.png)

根节点的信息熵是：

![](https://static001.geekbang.org/resource/image/9f/9b/9f01e1d1e8082e55850676da50a84f9b.png)

叶子节点：D1 D2 D3

D1(天气 = 晴天)={1-,2-,6+}

D2(天气 = 阴天)={3+,7-}

D3(天气 = 小雨)={4+,5-}

![](https://static001.geekbang.org/resource/image/85/7f/8537ab10a1a3747d22059bfbbd2aa17f.png)



优点：算法简单，通俗易懂
缺陷：1. 无法处理缺失值
          2. 只能处理离散值，无法处理连续值
          3. 用信息增益作为划分规则，存在偏向于选择取值较多的特征。因为特征取值越多，说明划分的 
              越细，不确定性越低，信息增益则越高
          4. 容易出现过拟合





- 信息增益率(C4.5算法)

C4.5:

优点：1. 能够处理缺省值
          2. 能对连续值做离散处理
          3. 使用信息增益比，能够避免偏向于选择取值较多的特征。因为信息增益比=信息增益/属性 
              熵，属性熵是根据属性的取值来计算的，一相除就会抵消掉
          4. 在构造树的过程中，会剪枝，减少过拟合
缺点：构造决策树，需要对数据进行多次扫描和排序，效率低

- 基尼指数(Cart算法)





